{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2, Part 1: Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Credit*: this notebook is based on FastML [tutorials](https://github.com/fastmachinelearning/hls4ml-tutorial/blob/master/part1_getting_started.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import torch, numpy and matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix the random seed to have reproducable the results. \n",
    "# Later you can try changeing the SEED to see how much does it influence the results\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia: *PyTorch is an open source machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Meta AI.*\n",
    "\n",
    "Let's do a few operations to get used to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random tensor\n",
    "t = torch.rand((4, 4))\n",
    "print(t)\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector\n",
    "a = torch.arange(16)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to a matrix\n",
    "a = a.reshape((4, -1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new tensor filled with ones\n",
    "b = torch.ones_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tensors \n",
    "b + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply tensors\n",
    "(2*b) * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix product of two tensors\n",
    "b.matmul(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The majority of particles produced in LHC events are unstable and immediately decay to lighter particles. The new particles can decay themselves to others in a so-called decay chain. Such a process terminates when the decay products are stable particles, e.g., charged pions. This collimated shower of particles with adjacent trajectories is called a *jet*. Jets are central to many physics studies at the LHC experiments. In particular, a successful physics program requires aggregating particles into jets (jet clustering), an accurate determination of the jet momentum (momentum measurement) and the identification of which particle kind started the shower (**jet tagging**).\n",
    "\n",
    "In this excercise you will learn how to train and evaluate a classifier that will predict which particle produced a given jet, a *jet tagger*. To this purpose we will download the dataset containing samples with 16 high-level features from [here](https://paperswithcode.com/dataset/hls4ml-lhc-jet-dataset). We will classify jets to five classes: produced by decay of top (*t*), Z (*z*) and W (*w*) boson, gluon (*g*) and quark (*q*).\n",
    "\n",
    "<img src='https://production-media.paperswithcode.com/datasets/JetDataset.png' width='300px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading, exploring and preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to download the dataset now\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "# In colab execute this line: X, y = data['data'].to_numpy(), data['target'].to_numpy()\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the dataset\n",
    "\n",
    "print('We have {} features in the dataset'.format(len(data['feature_names'])))\n",
    "print('Number of datapoints in the dataset {}'.format(X.shape[0]))\n",
    "print('Are X and y the same size? {}'.format(X.shape[0]==y.shape[0]))\n",
    "print('Our target classes for tagging: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0], X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw above, the **y** target is a string, e.g. 'g'. We need to modify it to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)\n",
    "print([(x,y) for x,y in zip(le.classes_, range(len(le.classes_)))])\n",
    "print(y_int[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this looks better. We can work with numbers. But wait, this still doesn't make sense. Why the distance between *q* and *t* is shorter than *q* and *w*? It's not really better to classify *q* as *t* rather than *w*, does it? We need to make this a \"one hot\" which will equalize the errors made by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_true = ohe.fit_transform(y_int.reshape(-1, 1))\n",
    "print(ohe.categories_)\n",
    "print(y_true[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the dataset. 80:20:20 (train, validation, test) split is usually a good start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_true, test_size=0.2, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=SEED)\n",
    "\n",
    "print('training:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('validation:')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('test:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset. Visualizing each feature will help us understand what do we use as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the features and plot a histogram\n",
    "\n",
    "for i in range(len(data['feature_names'])):\n",
    "    plt.hist(X[:,i], bins=50);\n",
    "    plt.title(data['feature_names'][i])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task: Try to visualize it again but for each class separatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['feature_names'])):\n",
    "    # TODO: Your code here\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could notice the differences in the scale of different features. We should normalize the dataset before training our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the input\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's construct a simple model. We'll use 3 hidden layers, each with 32 neurons. Each fully connected layer will be folowed by ReLU activation. The output layer has 5 nodes (one for each class). To get the probability distribution we use the softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's construct the model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "class JetTagger(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(JetTagger, self).__init__()\n",
    "        # Let's define our layers here.\n",
    "        self.fc1 = torch.nn.Linear(in_features, 32, bias=True) # Define the first layer (input: in_features and 32 outputs)\n",
    "        self.fc2 = torch.nn.Linear(32, 32, bias=True) # Define the second hidden layer \n",
    "        self.fc3 = torch.nn.Linear(32, 32, bias=True) # Define the third hidden layer \n",
    "        self.fc4 = torch.nn.Linear(32, out_features, bias=True) # Define the output layer \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Let's define out forward pass\n",
    "        x = F.relu(self.fc1(x)) # Pass through the first layer and relu activation\n",
    "        x = F.relu(self.fc2(x)) # Now through the second\n",
    "        x = F.relu(self.fc3(x)) # And third\n",
    "        x = F.softmax(self.fc4(x), dim=-1) # Our output should be normalized by softmax, i.e. summing to 1.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task: Pass correct arguments to match number of input and output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = JetTagger(_fix_me) #TODO: pass correct arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the model simply by printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the weights of a layer of interest, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe you will need to execute this line first:\n",
    "#!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the computational graph\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "net.eval()\n",
    "yhat = net(torch.zeros(1, 16))\n",
    "make_dot(yhat, params=dict(list(net.named_parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice visualization of the entire graph. But what if we just want see the architecutre?\n",
    "\n",
    "There are many tools, so let's try one of them. First we need to export the model to TorchScript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(net) \n",
    "model_scripted.save('myJetTagger.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to [netron](https://netron.app/) and click 'Open model'. Select your `myJetTagger.pt` file. It should show something like this:\n",
    "<img src=\"./assets/jettagger.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides the `Dataset` and `DataLoader` primitives to faciliate data handling, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). Let's use them!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to monitor our training let's write a helper class that will keep track of accuracy and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':1.5f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{avg' + self.fmt + '} ({name})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use simple SGD optimizer and crossentropy loss ($CE$):\n",
    "$$ CE=-\\sum_{i}^{C} t_i \\log s_i$$ where $t_i$ and $s_i$ are the ground truth and network outputs for each class $i$ in $C$.\n",
    "\n",
    "The model isn't very big, so this should just a moment on a regular CPU. For bigger models you'd like to use GPUs. You can increase number of epochs to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the most crucial part, where the learning happens. Take a moment to read the code to understand each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "acc, loss = AverageMeter('Accuracy'), AverageMeter('Loss')\n",
    "train_loss, val_acc, val_loss = [], [], []\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    net.train()\n",
    "    # Reset our meters\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    # This is just here because it's pretty \n",
    "    tr = trange(len(train_dataloader), file=sys.stdout)\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (torch.argmax(targets, dim=-1) == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        # Show the current results\n",
    "        tr.set_description('Epoch {}, {}, {}'.format(epoch+1, loss, acc))\n",
    "        tr.update(1)\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss.append(loss.avg)\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    net.eval()\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    tr = trange(len(val_dataloader), file=sys.stdout)\n",
    "\n",
    "    for inputs, targets in val_dataloader:\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (torch.argmax(targets, dim=-1) == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        tr.set_description('Validation, {}, {}'.format(loss, acc))\n",
    "        tr.update(1)\n",
    "\n",
    "    val_loss.append(loss.avg)\n",
    "    val_acc.append(acc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw loss and accuracy for the training and validation\n",
    "\n",
    "def draw_loss(data_train, data_val, data_acc, label=\"Loss\"):\n",
    "    \"\"\"Plots the training and validation loss\"\"\"\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel(\"Epoch\", horizontalalignment='right', x=1.0)\n",
    "    ax1.set_ylabel(\"Loss\", horizontalalignment='right', y=1.0)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    ax1.plot(data_train,\n",
    "             color='red',\n",
    "             label='Training loss')\n",
    "    ax1.plot(data_val,\n",
    "             color='blue',\n",
    "             label='Validation loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    ax2.plot(data_acc,\n",
    "             color='green',\n",
    "             label='Accuracy')\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "draw_loss(train_loss, val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the performance of the model, i.e. accuracy and make a the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = net(torch.tensor(X_test).unsqueeze(0).float())\n",
    "\n",
    "print(\"Accuracy for the test set: {0:.2f}\".format(\n",
    "    accuracy_score(\n",
    "        np.argmax(y_test, axis=1),\n",
    "        torch.argmax(y_pred, dim=-1).squeeze().numpy())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc(y_test, y_pred, labels):\n",
    "    for x, label in enumerate(labels):        \n",
    "        fpr, tpr, _ = roc_curve(y_test[:, x], y_pred[:, x])\n",
    "        plt.plot(tpr, fpr, label='{0} tagger, AUC = {1:.1f}'.format(label, auc(fpr, tpr)*100.), linestyle='-')\n",
    "    plt.semilogy()\n",
    "    plt.xlabel(\"Signal Efficiency\")\n",
    "    plt.ylabel(\"Background Efficiency\")\n",
    "    plt.ylim(0.001, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper left')  \n",
    "    \n",
    "plt.figure(figsize=(9, 9))\n",
    "plot_roc(y_test, y_pred.squeeze().detach().numpy(), le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this really doesn't work...\n",
    "### Your task: Try to fix the problem...\n",
    "Hint: Look at the loss, why is it decreasing so slowly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finshed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the simple adjustment you should get at least 70% accuracy. Can you do better? Go ahead and experiment with:\n",
    "* Make the network wider\n",
    "* Make the network deeper\n",
    "* Add L2 regularization\n",
    " * https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
    "* Set initial weights using Glorot initialization\n",
    " * https://pytorch.org/docs/stable/nn.init.html?highlight=xavier_normal#torch.nn.init.xavier_normal_\n",
    "* Add batch normalization\n",
    " * https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "* Add dropout\n",
    " * https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "* Change ReLU activation\n",
    " * https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "* Change the optimizer\n",
    " * https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
    " \n",
    "How do these changes affect training and the final accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2, Part 2: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will learn how to build and train a Convolutional Neural Network (CNN). For this exercise, we will use the dataset containing 872666 25x25 px *jet images* (see arXiv:1701.05927) and corresponding labels: 1 for signal, i.e. W boson and 0 for background, i.e. QCD, from [here](https://zenodo.org/record/269622/#.YtgOpEhBxe7).\n",
    "\n",
    "Traditional approaches to jet tagging rely on features, such as jet substructure, designed by experts that detect characteristic energy deposit patterns. In recent years, many studies applied computer vision for event reconstruction at particle colliders. This was obtained by projecting the lower level detector measurements of the emanating particles onto a cylindrical detector and then unwrapping the inner surface of the calorimeter on a rectangle. Such information was further interpreted as an image with calorimeter cells as pixels, where pixel intensity maps the energy deposit of the cell, i.e. **jet images**. The different appearance of these jets can be used as a handle to discriminate between them, i.e. **jet tagging**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional convolutional layer for image height $H$, width $W$, number of input channels $C$, number of output kernels (filters) $N$, and kernel height $J$ and width $K$ is given by:\n",
    "\n",
    "\\begin{align}\n",
    "\\label{convLayer}\n",
    "\\boldsymbol{Y}[v,u,n] &= \\boldsymbol{\\beta}[n] + \\sum_{c=1}^{C} \\sum_{j=1}^{J} \\sum_{k=1}^{K} \\boldsymbol{X}[v+j,u+k,c]\\, \\boldsymbol{W}[j,k,c,n]\\,,\n",
    "\\end{align}\n",
    "\n",
    "where $Y$ is the output tensor of size $V \\times U \\times N$, $W$ is the weight tensor of size $J \\times K \\times C \\times N$ and $\\beta$ is the bias vector of length $N$ .\n",
    "\n",
    "The example below uses a sharpening filter with $C=1$, $J=K=3$:\n",
    "\n",
    "<img src=\"assets/convolution.gif\"/>[Credit](https://towardsdatascience.com/types-of-convolution-kernels-simplified-f040cb307c37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write our own convolution operation and see how does it perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel, stride=None, padding=None):\n",
    "    \n",
    "    H = img.shape[0]\n",
    "    W = img.shape[1]\n",
    "    \n",
    "    # Let's assume S=J=K\n",
    "    S = kernel.shape[0]\n",
    "    filt_h = kernel.shape[1]\n",
    "    \n",
    "    # In our case we only have one filer, so n=1. We will drop the 3rd dim for simplicity\n",
    "    img_out = np.zeros((H+1,W+1))\n",
    "\n",
    "    # Nested loops over V and U\n",
    "    for v in range(S//2, H-S//2):\n",
    "        for u in range(S//2, W-S//2):\n",
    "            img_out[v, u] = np.sum(img[v-S//2:v+S//2+1,u-S//2:u+S//2+1]*kernel)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and show an image\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('assets/cms.png')\n",
    "plt.imshow(img);\n",
    "\n",
    "# This is the CMS detecor BTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of filters were hand-crafted a long time ago. Apps on your phone are often still using these man-made kernes. We are going to to use an classic edge detection filter. You can read more about it [here](https://en.wikipedia.org/wiki/Sobel_operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our filter\n",
    "\n",
    "sobel_filter = np.array([[1,2,1], [0,0,0], [-1, -2, -1]])\n",
    "sobel_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform our convolution and show the result\n",
    "\n",
    "img_edges = convolution(img[:, :, 0], sobel_filter)\n",
    "plt.imshow(img_edges, cmap='binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges should be white or black colored (depending on the direction of change), gray areas mean no edge. We have used a vertical variant of the sobel filter. We can see the edges quite clear. Let's try to see if there is any difference when we apply a horizontal version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform our convolution and show the result\n",
    "\n",
    "img_edges = convolution(img[:, :, 0], sobel_filter.T)\n",
    "plt.imshow(img_edges, cmap='binary');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a check if our input image matches the shape of the output one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,0].shape == img_edges.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh... But that's expected. Do you know why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride and padding\n",
    "\n",
    "There are two important parameters that we did not implement, i.e. stride and padding.\n",
    "\n",
    "**Stride** contols by how many pixels do we move in every loop. Image from [here](https://www.oreilly.com/library/view/hands-on-transfer-learning/9781788831307/df581a77-c057-4978-a25e-564cb1ab5bb3.xhtml).\n",
    "\n",
    "![](./assets/stride.png)\n",
    "\n",
    "**Padding** expands the input by adding border to the image, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.random((4,4))\n",
    "print(A)\n",
    "print(np.pad(A, 1, constant_values=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task: Implement a stride and padding in the convolution function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Operation\n",
    "\n",
    "Pooling layers are used to reduce the dimensions of the feature maps, simultaneously reducting number of learnable parameters and speeding forward and backward pass. The operation slides a filter over the feature map which either outputs and average or max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(img, size):\n",
    "    # Mind that I used size as stride as in preactis they are often equal. As an optional exercise you can correct this method, i.e `def pooling(img, size, stride)`\n",
    "    \n",
    "    H = img.shape[0]\n",
    "    W = img.shape[1]\n",
    "\n",
    "    img_out = np.zeros((H//size,W//size))\n",
    "\n",
    "    # Nested loops over V and U\n",
    "    for v in range(0, H//size):\n",
    "        for u in range(0, W//size):\n",
    "            img_out[v, u] = np.max(img[v*size:v*size+size,u*size:u*size+size])\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform our pooling and show the result\n",
    "\n",
    "img_pool = pooling(img[:, :, 0], 4)\n",
    "plt.imshow(img_pool);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the dimensionality indeed decreased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task: change max pooling to average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build owr networks\n",
    "\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class LeNet5Tagger(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5Tagger, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.pool1 = torch.nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = torch.nn.AvgPool2d(2, 2)\n",
    "        self.fc1 = torch.nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=-1)\n",
    "    \n",
    "class FullyConnectedTagger(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(FullyConnectedTagger, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features, 64, bias=True)\n",
    "        self.fc2 = torch.nn.Linear(64, 64, bias=True)\n",
    "        self.fc3 = torch.nn.Linear(64, 32, bias=True)\n",
    "        self.fc4 = torch.nn.Linear(32, out_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 25*25)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=-1)\n",
    "        return x\n",
    "    \n",
    "fcn = FullyConnectedTagger(25*25, 2)\n",
    "cnn = LeNet5Tagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to download the dataset from [here](https://zenodo.org/record/269622/#.YtgEwUhBxe7). This can take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q 'https://zenodo.org/record/269622/files/jet-images_Mass60-100_pT250-300_R1.25_Pix25.hdf5?download=1' -O './jet_images.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file that we just downloaded\n",
    "\n",
    "import h5py\n",
    "dataset = h5py.File('jet_images.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how does the W boson looks like\n",
    "\n",
    "average_w = np.mean(dataset['image'][:100000][dataset['signal'][:100000] == 1], axis=0)\n",
    "plt.imshow(average_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here is an average of QCD\n",
    "\n",
    "average_qcd = np.mean(dataset['image'][:100000][dataset['signal'][:100000] == 0], axis=0)\n",
    "plt.imshow(average_qcd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "class H5Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = torch.Tensor(images)\n",
    "        self.labels = torch.Tensor(labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    H5Dataset(\n",
    "        torch.Tensor(dataset['image'][:100000]).unsqueeze(1),\n",
    "        torch.LongTensor(dataset['signal'][:100000])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    H5Dataset(\n",
    "        torch.Tensor(dataset['image'][100000:150000]).unsqueeze(1),\n",
    "        torch.LongTensor(dataset['signal'][100000:150000])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training and evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "acc, loss = AverageMeter('Accuracy'), AverageMeter('Loss')\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    cnn.train()\n",
    "    # Reset our meters\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    # This is just here because it's pretty \n",
    "    tr = trange(len(train_dataloader), file=sys.stdout)\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        outputs = cnn(inputs)\n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        # Show the current results\n",
    "        tr.set_description('Epoch {}, {}, {}'.format(epoch+1, loss, acc))\n",
    "        tr.update(1)\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    cnn.eval()\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    tr = trange(len(val_dataloader), file=sys.stdout)\n",
    "\n",
    "    for inputs, targets in val_dataloader:\n",
    "\n",
    "        outputs = cnn(inputs)\n",
    "\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        tr.set_description('Validation, {}, {}'.format(loss, acc))\n",
    "        tr.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "acc, loss = AverageMeter('Accuracy'), AverageMeter('Loss')\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    fcn.train()\n",
    "    # Reset our meters\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    # This is just here because it's pretty \n",
    "    tr = trange(len(train_dataloader), file=sys.stdout)\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        outputs = fcn(inputs)\n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        # Show the current results\n",
    "        tr.set_description('Epoch {}, {}, {}'.format(epoch+1, loss, acc))\n",
    "        tr.update(1)\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    fcn.eval()\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    tr = trange(len(val_dataloader), file=sys.stdout)\n",
    "\n",
    "    for inputs, targets in val_dataloader:\n",
    "\n",
    "        outputs = fcn(inputs)\n",
    "\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        tr.set_description('Validation, {}, {}'.format(loss, acc))\n",
    "        tr.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the accuracy on the test data\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_images = torch.Tensor(dataset['image'][200000:250000]).unsqueeze(1)\n",
    "y_truth = dataset['signal'][200000:250000]\n",
    "y_pred_cnn = cnn(test_images)\n",
    "y_pred_fcn = fcn(test_images)\n",
    "\n",
    "print(\"Accuracy for the CNN: {0:.2f}\".format(\n",
    "    accuracy_score(\n",
    "        y_truth,\n",
    "        torch.argmax(y_pred_cnn, dim=-1).squeeze().numpy())\n",
    "))\n",
    "\n",
    "print(\"Accuracy for the fully connected: {0:.2f}\".format(\n",
    "    accuracy_score(\n",
    "        y_truth,\n",
    "        torch.argmax(y_pred_fcn, dim=-1).squeeze().numpy())\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task: visualize ROC curves and compute the AUC for both networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN is a little better than fully connected network. But we use much less parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size\n",
    "\n",
    "print(\"Numer of parameters in CNN: {}\".format(sum(p.numel() for p in cnn.parameters())))\n",
    "print(\"Numer of parameters in FCN: {}\".format(sum(p.numel() for p in fcn.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and experiment with:\n",
    "* Make the network wider (more filters)\n",
    "* Make the network deeper\n",
    "* Change the size of the kernel\n",
    "* Change to average pooling\n",
    "* Add batch normalization\n",
    "\n",
    "How do these changes affect training and the final accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "This is the last part for today. With transfer learning we can apply knowledge learned on one task to a new one. Why? Depending on the size deep neural networks require hours, days or weeks to train. We can cut this time by applying pre-trained weights used for image recognition. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "def weights_init(m):\n",
    "    init.kaiming_uniform_(m.weight.data)\n",
    "\n",
    "# Load the pretrained model from torchvision\n",
    "model = mobilenet_v2(pretrained=True)\n",
    "\n",
    "# # Replace the first layer to match the input\n",
    "model.features[0][0] = torch.nn.Conv2d(1,\n",
    "                              32,\n",
    "                              kernel_size=3,\n",
    "                              stride=2,\n",
    "                              padding=(1,1),\n",
    "                              bias=False)\n",
    "model.features[0][0].apply(weights_init)\n",
    "\n",
    "# # Replace the layer to match the input\n",
    "model.classifier[1] = torch.nn.Linear(1280, 2, bias=True)\n",
    "model.classifier[1].apply(weights_init)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MobileNetv2. You can read more about it [here](https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain. It can be a bit intense for a CPU, but let's try\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 2\n",
    "\n",
    "acc, loss = AverageMeter('Accuracy'), AverageMeter('Loss')\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Reset our meters\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    # This is just here because it's pretty \n",
    "    tr = trange(len(train_dataloader), file=sys.stdout)\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        # Show the current results\n",
    "        tr.set_description('Epoch {}, {}, {}'.format(epoch+1, loss, acc))\n",
    "        tr.update(1)\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    model.eval()\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    tr = trange(len(val_dataloader), file=sys.stdout)\n",
    "\n",
    "    for inputs, targets in val_dataloader:\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (targets == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "\n",
    "        tr.set_description('Validation, {}, {}'.format(loss, acc))\n",
    "        tr.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last exercise, would you like to try a different architecure? [Here](https://pytorch.org/vision/0.11/models.html), check the documentation. Mind that some networks will be too big to train a CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
